{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l_DE4APDs2c"
      },
      "source": [
        "# ENSEMBLE MODEL\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvqA-vFcSi0l"
      },
      "source": [
        "Make sure you add the models shared drive into MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/__main__.py\", line 29, in <module>\n",
            "    from pip._internal.cli.main import main as _main\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 9, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/build_env.py\", line 15, in <module>\n",
            "    from pip._vendor.certifi import where\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/certifi/__init__.py\", line 1, in <module>\n",
            "    from .core import contents, where\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/certifi/core.py\", line 46, in <module>\n",
            "    from importlib.resources import path as get_path, read_text\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/resources.py\", line 4, in <module>\n",
            "    from . import _common\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/_common.py\", line 12, in <module>\n",
            "    from ._adapters import wrap_spec\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 674, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\n",
            "  File \"<frozen importlib._bootstrap>\", line 541, in _init_module_attrs\n",
            "KeyboardInterrupt\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Anna/Library/Python/3.10/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: six>=1.5 in /Users/Anna/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.4.1.post1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.13.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.39.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/Anna/Library/Python/3.10/lib/python/site-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/Anna/Library/Python/3.10/lib/python/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install torch torchvision torchaudio\n",
        "%pip install pandas\n",
        "%pip install scikit-learn\n",
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F2wxpiuYGZDL"
      },
      "outputs": [],
      "source": [
        "import statistics\n",
        "import torch\n",
        "import re\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import os\n",
        "import sklearn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Ensemble_Model():\n",
        "  def __init__(self, text):\n",
        "    self.text = text\n",
        "    self.model = None\n",
        "    self.mlp_classifier = None\n",
        "    self.svm_classifier = None\n",
        "    self.nb_classifier = None\n",
        "    self.tfidf_vec = None\n",
        "    self.tfidf_text = None\n",
        "    self.cv_text = None\n",
        "    self.cv = None\n",
        "    self.tfidf = None\n",
        "    self.tokenizer = None\n",
        "    self.tfm_pred_label = None\n",
        "    self.tfm_pred_score = None\n",
        "    self.mlp_pred_label = None\n",
        "    self.mlp_pred_score = None\n",
        "    self.svm_pred_label = None\n",
        "    self.svm_pred_score = None\n",
        "    self.nb_pred_label = None\n",
        "    self.nb_pred_score = None\n",
        "    self.model_list = None\n",
        "\n",
        "  def import_models(self):\n",
        "    self.model = AutoModelForSequenceClassification.from_pretrained(\"large_files/pretrained models/transformer\")\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(\"large_files/pretrained models/transformer\")\n",
        "\n",
        "    with open('large_files/pretrained models/mlp.pkl', 'rb') as f:\n",
        "      self.mlp_classifier = pickle.load(f)\n",
        "\n",
        "    with open('large_files/pretrained models/tfidfMLP.pkl', 'rb') as f:\n",
        "      self.tfidf_vec = pickle.load(f)\n",
        "\n",
        "    with open('large_files/pretrained models/svm.pkl', 'rb') as f:\n",
        "      self.svm_classifier = pickle.load(f)\n",
        "\n",
        "    with open('large_files/pretrained models/vectorizer.pkl', 'rb') as f:\n",
        "      self.cv = pickle.load(f)\n",
        "\n",
        "    with open('large_files/pretrained models/tfidf.pkl', 'rb') as f:\n",
        "      self.tfidf = pickle.load(f)\n",
        "\n",
        "    with open('large_files/pretrained models/naivebayes.pkl', 'rb') as f:\n",
        "      self.nb_classifier = pickle.load(f)\n",
        "\n",
        "  def text_processing(self, text):\n",
        "    input_text = re.sub(r'[\\'\"‘’“”]', '', text)\n",
        "    input_text = re.sub('^.*\\(Reuters\\)\\s*-\\s*', '', input_text)\n",
        "    input_text = [input_text]\n",
        "    self.cv_text = self.cv.transform(input_text)\n",
        "    self.tfidf_text = self.tfidf.transform(self.cv_text)\n",
        "    return input_text\n",
        "\n",
        "  def define_labels(prob):\n",
        "    if prob >= 0.5:\n",
        "      pred_class = \"Real\"  # Real news\n",
        "    else:\n",
        "      pred_class = \"Fake\"  # Fake news\n",
        "    return pred_class\n",
        "\n",
        "  def transformers(self,input_text):\n",
        "    inputs = self.tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Forward pass through the model to obtain logits\n",
        "    with torch.no_grad():\n",
        "        outputs = self.model(**inputs)\n",
        "\n",
        "    # Get the predicted class label\n",
        "    tfm_pred = torch.sigmoid(outputs.logits).squeeze().tolist()  # Assuming binary classification\n",
        "    if tfm_pred >= 0.5:\n",
        "        self.tfm_pred_label = \"Real\"\n",
        "    else:\n",
        "        self.tfm_pred_label = \"Fake\"\n",
        "    self.tfm_pred_score = torch.sigmoid(outputs.logits).item()\n",
        "    return\n",
        "\n",
        "  def mlp(self,input_text):\n",
        "    input_tfidf = self.tfidf_vec.transform(input_text)\n",
        "    mlp_prob = self.mlp_classifier.predict_proba(input_tfidf)\n",
        "    self.mlp_pred_label = Ensemble_Model.define_labels(mlp_prob[0][1])\n",
        "    self.mlp_pred_score = mlp_prob[0][1]\n",
        "    return\n",
        "\n",
        "  def svm(self,input_text):\n",
        "    svm_prob = self.svm_classifier.decision_function(self.tfidf_text)\n",
        "    self.svm_pred_label = Ensemble_Model.define_labels(1 / (1 + np.exp(-svm_prob))[0])\n",
        "    self.svm_pred_score  = 1 / (1 + np.exp(-svm_prob))[0]\n",
        "    return\n",
        "\n",
        "  def naivebayes(self,input_text):\n",
        "    nb_prob = self.nb_classifier.predict_proba(self.tfidf_text)\n",
        "    self.nb_pred_label = Ensemble_Model.define_labels(nb_prob[0][1])\n",
        "    self.nb_pred_score = nb_prob[0][1]\n",
        "    return\n",
        "\n",
        "  def predict_list(self):\n",
        "    if self.nb_classifier == None:\n",
        "      Ensemble_Model.import_models(self)\n",
        "    text = Ensemble_Model.text_processing(self,self.text)\n",
        "    Ensemble_Model.transformers(self,text)\n",
        "    Ensemble_Model.mlp(self,text)\n",
        "    Ensemble_Model.svm(self,text)\n",
        "    Ensemble_Model.naivebayes(self,text)\n",
        "\n",
        "    self.model_list = [\"Transformers\", \"MLP\", \"SVM\", \"Naive Bayes\"]\n",
        "    self.label_list = [self.tfm_pred_label, self.mlp_pred_label, self.svm_pred_label, self.nb_pred_label]\n",
        "    self.score_list = [self.tfm_pred_score, self.mlp_pred_score, self.svm_pred_score, self.nb_pred_score]\n",
        "    return\n",
        "\n",
        "  def predict_df(self):\n",
        "    if self.model_list == None:\n",
        "      Ensemble_Model.predict_list(self)\n",
        "\n",
        "    result_df = pd.DataFrame({\"Model\": self.model_list,\n",
        "                            \"Label\": self.label_list,\n",
        "                            \"Score\": self.score_list})\n",
        "    print(\"\\n PROBABILTY SCORE OF EACH MODEL\")\n",
        "    print(result_df)\n",
        "    return\n",
        "\n",
        "  def predict(self):\n",
        "    if self.model_list == None:\n",
        "      Ensemble_Model.predict_list(self)\n",
        "\n",
        "    fake_count = self.label_list.count(\"Fake\")\n",
        "    real_count = self.label_list.count(\"Real\")\n",
        "    if fake_count > real_count:\n",
        "      result_label = \"Fake\"\n",
        "      result_score = statistics.mean(self.score_list[i] for i in range(4) if self.score_list[i] < 0.5)\n",
        "    elif fake_count < real_count:\n",
        "      result_label = \"Real\"\n",
        "      result_score = statistics.mean(self.score_list[i] for i in range(4) if self.score_list[i] > 0.5)\n",
        "    else:\n",
        "      result_score = statistics.mean(self.score_list[i] for i in range(4))\n",
        "      if result_score >= 0.5:\n",
        "        result_label = \"Real\"\n",
        "      else:\n",
        "        result_label = \"Fake\"\n",
        "\n",
        "    print(\"Predicted label: \", result_label)\n",
        "    print(\"Predicted score: \", result_score)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obx00rWrRQlw",
        "outputId": "bc7d3d30-6dc7-48d8-cbc2-f044c2e15570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted label:  Fake\n",
            "Predicted score:  0.4535598842154332\n",
            "\n",
            " PROBABILTY SCORE OF EACH MODEL\n",
            "          Model Label     Score\n",
            "0  Transformers  Real  0.626929\n",
            "1           MLP  Fake  0.406646\n",
            "2           SVM  Fake  0.475583\n",
            "3   Naive Bayes  Fake  0.478451\n"
          ]
        }
      ],
      "source": [
        "text = input(\"Input text \\n\" )\n",
        "Ensemble_Model(f\"\"\"{text}\"\"\").predict()\n",
        "Ensemble_Model(f\"\"\"{text}\"\"\").predict_df()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
